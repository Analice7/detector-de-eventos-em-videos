import torch
import streamlit as st
import time
import pandas as pd
import numpy as np
import altair as alt
import cv2
import tempfile
import os
from pathlib import Path
torch.classes.__path__ = [os.path.join(torch.__path__[0], torch.classes.__file__)] 

# Importando os m√≥dulos necess√°rios do seu c√≥digo existente
from src.preprocessing.dataProcesser import download_youtube_video, extrair_frames
from src.preprocessing.keypoints import extract_keypoints_from_frames
from src.preprocessing.features import process_video_keypoints

# Fun√ß√£o para carregar o modelo treinado
def load_model(model_path='best_lstm_model.pth'):
    try:
        # Importar a classe PoseRNN do m√≥dulo train.py
        from src.training.train import PoseRNN, Config
        
        # Determinar o tamanho de entrada a partir dos dados de treinamento
        input_size = 72  # Substitua pelo tamanho correto baseado nas suas caracter√≠sticas
        
        # Criar modelo com a mesma arquitetura usada no treinamento
        model = PoseRNN(input_size, rnn_type='lstm')
        
        # Carregar os pesos
        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
        
        # Colocar o modelo em modo de avalia√ß√£o
        model.eval()
        
        return model
    except Exception as e:
        st.error(f"Erro ao carregar o modelo: {e}")
        return None

# Fun√ß√£o para fazer predi√ß√µes
def predict(model, features, seq_length=10):
    try:
        # Preparar os dados para o modelo
        n_frames, n_features = features.shape
        
        # Criar sequ√™ncias
        predictions = []
        confidences = []
        
        with torch.no_grad():
            for i in range(0, n_frames - seq_length + 1, seq_length // 2):  # 50% de sobreposi√ß√£o
                seq = features[i:i+seq_length]
                if len(seq) == seq_length:
                    # Converter para tensor
                    seq_tensor = torch.FloatTensor(seq).unsqueeze(0)  # Add batch dimension
                    
                    # Fazer predi√ß√£o
                    output = model(seq_tensor)
                    
                    # Aplicar softmax para obter probabilidades
                    probs = torch.nn.functional.softmax(output, dim=1)
                    
                    # Obter classe com maior probabilidade
                    _, predicted = torch.max(output.data, 1)
                    
                    # Armazenar resultados
                    predictions.append(predicted.item())
                    confidences.append(probs[0, 1].item())  # Probabilidade da classe 1 (agress√£o)
        
        return predictions, confidences
    except Exception as e:
        st.error(f"Erro na predi√ß√£o: {e}")
        return [], []

def process_video(youtube_url, progress_callback=None):
    try:
        # 1. Download do v√≠deo
        progress_callback("Baixando v√≠deo...", 0.1)
        video_path, title = download_youtube_video(youtube_url)
        
        if not video_path:
            raise Exception("Falha ao baixar o v√≠deo. Verifique se o URL √© v√°lido e tente novamente.")
        
        # 2. Extra√ß√£o de frames
        progress_callback("Extraindo frames...", 0.3)
        frames = extrair_frames(video_path, f=5)
        if not frames or len(frames) == 0:
            raise Exception("Nenhum frame extra√≠do do v√≠deo")
        
        # 3. Extra√ß√£o de keypoints
        progress_callback("Detectando poses humanas...", 0.5)
        temp_dir = tempfile.mkdtemp()
        keypoints_dir = os.path.join(temp_dir, "keypoints")
        os.makedirs(keypoints_dir, exist_ok=True)
        extract_keypoints_from_frames(frames, keypoints_dir)
        
        # Verificar se os keypoints foram extra√≠dos
        keypoints_files = [f for f in os.listdir(keypoints_dir) if f.startswith("frame_")]
        if not keypoints_files:
            raise Exception("Nenhum keypoint extra√≠do dos frames")
        
        # 4. Extra√ß√£o de caracter√≠sticas
        progress_callback("Extraindo caracter√≠sticas...", 0.7)
        features_dir = os.path.join(temp_dir, "features")
        os.makedirs(features_dir, exist_ok=True)
        features_dict = process_video_keypoints(keypoints_dir, features_dir)
        
        if not features_dict:
            raise Exception("Falha ao extrair caracter√≠sticas")
        
        # Preparar sequ√™ncia de caracter√≠sticas para classifica√ß√£o
        features_file = os.path.join(features_dir, "features.npy")
        if os.path.exists(features_file):
            features_sequence = np.load(features_file)
        else:
            # Fallback caso o arquivo n√£o exista
            feature_keys = sorted(features_dict.keys())
            if not feature_keys:
                raise Exception("Dicion√°rio de caracter√≠sticas vazio")
                
            n_frames = len(features_dict[feature_keys[0]])
            features_sequence = np.zeros((n_frames, len(feature_keys)))
            for i, key in enumerate(feature_keys):
                features_sequence[:, i] = features_dict[key]
        
        # 5. Classifica√ß√£o com o modelo
        progress_callback("Classificando comportamento...", 0.9)
        model = load_model()
        if not model:
            raise Exception("Falha ao carregar o modelo")
            
        predictions, confidences = predict(model, features_sequence)
        if not predictions or len(predictions) == 0:
            raise Exception("Nenhuma predi√ß√£o gerada")
        
        # 6. Resultados finais
        progress_callback("Finalizando an√°lise...", 1.0)
        
        # Determinar resultado geral
        avg_confidence = np.mean(confidences) if confidences else 0.5
        
        # Selecionar frame cr√≠tico
        if confidences and frames:
            max_confidence_index = min(np.argmax(confidences), len(frames)-1)
            critical_frame = frames[max_confidence_index]
        else:
            critical_frame = frames[-1] if frames else None
        
        return {
            'video_title': title,
            'confidences': confidences,
            'avg_confidence': avg_confidence,
            'frames': frames,
            'critical_frame': critical_frame,
            'max_confidence_index': np.argmax(confidences) if confidences else 0,
            'success': True
        }
    
    except Exception as e:
        st.error(f"Erro no processamento: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

def main():
    # Configura√ß√£o da p√°gina
    st.set_page_config(
        page_title="Detector de Agress√µes em V√≠deos",
        page_icon="üé¨",
        layout="wide"
    )
    
    # T√≠tulo e descri√ß√£o
    st.title("üé¨ Sistema de Detec√ß√£o de Agress√µes em V√≠deos")
    st.markdown("""
    Este sistema analisa v√≠deos para detectar poss√≠veis ocorr√™ncias de agress√µes f√≠sicas
    utilizando modelos de estimativa de poses humanas e Redes Neurais Recorrentes.
    """)
    
    # Sidebar
    with st.sidebar:
        st.header("Sobre o Sistema")
        st.info("""
        **Projeto de Vis√£o Computacional**
        
        Este sistema utiliza t√©cnicas avan√ßadas de vis√£o computacional 
        e aprendizado profundo para detectar comportamentos caracter√≠sticos 
        de agress√µes f√≠sicas em v√≠deos de c√¢meras de seguran√ßa.
        
        O pipeline de processamento inclui:
        1. Extra√ß√£o de frames do v√≠deo
        2. Detec√ß√£o de poses com YOLOv8
        3. Extra√ß√£o de caracter√≠sticas dos movimentos
        4. Classifica√ß√£o por Redes Neurais Recorrentes
        """)
        
        st.divider()
        st.markdown("Desenvolvido para disciplina de T√≥picos Especiais em IA")
    
    # Formul√°rio principal
    st.header("An√°lise de V√≠deo")
    
    with st.form(key="video_form"):
        youtube_url = st.text_input(
            "Link do v√≠deo do YouTube:",
            placeholder="Ex: https://www.youtube.com/watch?v=..."
        )
        
        submit_button = st.form_submit_button(label="Analisar V√≠deo")
    
    # L√≥gica ap√≥s o envio do formul√°rio
    if submit_button and youtube_url:
        # Exibi√ß√£o do link fornecido
        st.success(f"Link do v√≠deo recebido: {youtube_url}")
        
        # Processamento completo com uma √∫nica barra de progresso
        with st.spinner("Analisando v√≠deo..."):
            # Container para mostrar o progresso geral
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Callback para atualizar o progresso
            def update_progress(message, progress):
                status_text.text(message)
                progress_bar.progress(progress)
            
            # Processar o v√≠deo (substituir pela implementa√ß√£o real)
            # Para teste da interface, podemos usar um processamento simulado
            # Processar o v√≠deo
            try:
                results = process_video(youtube_url, update_progress)
                
                if not results or not results.get('success', False):
                    st.error(f"Erro ao processar o v√≠deo: {results.get('error', 'Erro desconhecido')}")
                    
                    # Oferecer op√ß√£o de visualizar dados simulados
                    if st.button("Visualizar exemplo com dados simulados"):
                        # Simular resultados para demonstra√ß√£o
                        status_text.text("Gerando visualiza√ß√£o com dados simulados...")
                        time.sleep(1)
                        results = {
                            'video_title': "Simula√ß√£o - " + youtube_url,
                            'confidences': np.clip(0.5 + 0.5 * np.sin(np.arange(0, 30, 1)/3) + np.random.normal(0, 0.1, 30), 0, 1),
                            'avg_confidence': 0.67,
                            'frames': [None] * 30,  # Placeholder
                            'critical_frame': None,
                            'max_confidence_index': 15,
                            'success': True
                        }
                    else:
                        # Encerrar o processamento aqui se n√£o quiser dados simulados
                        progress_bar.empty()
                        status_text.empty()
                        st.stop()
                
                status_text.text("An√°lise conclu√≠da!")
                
            except Exception as e:
                st.error(f"Erro durante o processamento: {str(e)}")
                progress_bar.empty()
                status_text.empty()
                st.stop()
            
            if not results:
                # Simular resultados para teste da interface
                status_text.text("Simulando resultados para teste...")
                time.sleep(1)
                results = {
                    'video_title': "V√≠deo de exemplo",
                    'confidences': np.clip(0.5 + 0.5 * np.sin(np.arange(0, 30, 1)/3) + np.random.normal(0, 0.1, 30), 0, 1),
                    'avg_confidence': 0.67,
                    'frames': [None] * 30,  # Placeholder
                    'critical_frame': None,
                    'max_confidence_index': 15
                }
            
            status_text.text("An√°lise conclu√≠da!")
        
        # Exibi√ß√£o dos resultados
        st.header("Resultados da An√°lise")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Probabilidade de agress√£o
            result_probability = results['avg_confidence']
            st.metric(
                label="Probabilidade de Agress√£o", 
                value=f"{result_probability:.2%}"
            )
            
            # Conclus√£o baseada na probabilidade
            confidence_threshold = 0.7  # Limiar para classifica√ß√£o
            if result_probability > confidence_threshold:
                st.error("‚ö†Ô∏è **ALERTA:** Comportamento de agress√£o f√≠sica detectado!")
            else:
                st.success("‚úÖ Nenhum comportamento de agress√£o detectado.")
        
        with col2:
            # Gr√°fico de confian√ßa ao longo do tempo
            st.subheader("Confian√ßa ao longo do v√≠deo")
            
            chart_data = pd.DataFrame({
                'Frame': np.arange(0, len(results['confidences'])),
                'Confian√ßa': results['confidences']
            })
            
            chart = alt.Chart(chart_data).mark_line().encode(
                x='Frame',
                y=alt.Y('Confian√ßa', scale=alt.Scale(domain=[0, 1]))
            ).properties(height=250)
            
            st.altair_chart(chart, use_container_width=True)
        
        # Se√ß√£o para frames principais detectados
        st.subheader("Momento cr√≠tico detectado")
        
        # Identificando o momento com maior probabilidade
        max_confidence_index = results['max_confidence_index']
        max_confidence_value = results['confidences'][max_confidence_index]
        
        # Se temos um frame cr√≠tico real, mostr√°-lo
        if results['critical_frame'] is not None:
            # Converter o frame para formato que o streamlit pode exibir
            critical_frame = cv2.cvtColor(results['critical_frame'], cv2.COLOR_BGR2RGB)
            st.image(
                critical_frame,
                caption=f"Momento de maior probabilidade de agress√£o ({max_confidence_value:.2%}) no frame {max_confidence_index}"
            )
        else:
            # Placeholder para testes da interface
            st.image(
                "https://via.placeholder.com/800x450?text=Momento+Cr√≠tico+de+Agress√£o",
                caption=f"Momento de maior probabilidade ({max_confidence_value:.2%}) no frame {max_confidence_index}"
            )

if __name__ == "__main__":
    main()